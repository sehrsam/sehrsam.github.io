{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a829c3a-1739-4a99-98d4-6b7652983070",
   "metadata": {},
   "source": [
    "Tinit Gebru Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2e828-6d47-4777-a409-8c984dfb98ca",
   "metadata": {},
   "source": [
    "This week, Timnit Gebru is going to be talking to our Machine Learning class, and will be giving a talk that is open for anyone to attend on Thursday at 7 pm. Gebru is a stanford educated computer science researcher who has worked for companies such as Google, Amazon and Microsoft, though she currently works as an independent researcher. Her research has been focused on the effects of algorithmic bias and how machine learning models often discriminate against people, such as in her paper “Gender Shades” which exposed how facial recognition software was significantly worse at distinguishing faces of women and people of color, or in the paper that led to her firing at Google,  \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\". \n",
    "\n",
    "In her talk, Gebru discusses the issues of machine learning processes on real world data. One thing that she mentions is how computer scientists often speak and act as if what they do somehow transcends the world around them, as if they are not affected by the realities of the world, and so their algorithms and research should similarly be above this. She brings up a quote from Seeta Pena Gangadharan, which highlights how computer scientists think of their work in terms of how it can be used to examine the real world, ignoring how the real world impacts the decisions and algorithms that are made.\n",
    "\n",
    "Gebru then discusses her study Gender Shades, discussing how she and her research partner went about it and some of the flawed reasoning behind the study. One such reason is the issue with race, where she highlighted how race is a social construct, and how a person's “race” is dependent upon who is observing, giving examples such as how during apartheid era South Africa a chinese person would be classified as black while a japanese one would be classified as white. She then discusses how the publicly available datasets where mainly white and mainly male, before showing how datasets in general are extremely euro-centric, meaning that computer vision processes will be less useful in many areas.\n",
    "\n",
    "She then shows examples of of how bias inherent in a dataset can be amplified by machine learning algorithms, using images of cooking, soap vs spices and weddings, where algorithms misclassified images because they did not fit with eurocentric norms. She then discusses how these issues apply to not only machine learning models but also in regular studies, such as in crash test dummies or drug trials, the results of which led to women and children being disproportionately harmed.\n",
    "\n",
    "Timnit then discusses how people have begun to acknowledge that these datasets may be flawed, but that little has been done to fix them, and that which has been done has been done in a predatory manner. She then mentions how even when diverse datasets are made, they often are used in ways that harm people, and seldom are the peoples whose faces and data are used see any benefits. She shows how police have used facial recognition software in a completely unregulated manner, and how even when there are systems in place they often ignore them, and diminish civil liberties. She then mentions how these tools are often trusted because of the way that people view automation, which can lead to people being unjustly incarcerated.\n",
    "\n",
    "She then talks about who is affected by computer vision the most, showing how it is minorities and marginalized communities, and how even when there are large groups protesting and acting against these issues they are often made up of people who have power and influence, thus not the marginalized minorities.\n",
    "\n",
    "tl/dr: In this talk, Timnit Gebru discusses the historical, present and future issues surrounding computer vision and facial recognition databases.\n",
    "\n",
    "\n",
    "Question: Do you think that the ethical concerns around computer vision are great enough that you think no work should be done in the field, as any progress even towards a noble goal could be used to diminish civil liberties and harm people?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b2ab26",
   "metadata": {},
   "source": [
    "In her talks, both to our class and in her open talk, Timnit Gebru discussed the issues surrounding AI. The main focus however, was on who are the ones who are in control and becoming more influential and powerful as a result. Timnit showed the progression of the eugenics movement, showing how it has often been widely accepted by powerful people, and showed the line from modern eugenics movements such as effective altruism go back to the early eugenics movements with the goal of removing negative traits from the human race. She then showed how various influential tech developers and investors believe these principles.\n",
    "\n",
    "She also talked about how the goal of AGI has influenced the development of AI systems, and how all progress towards this goal has been harmful for many vulnerable peoples. The idea of AGI is also one that leads towards centralization of power, as the ultimate goal of one all powerful machine would mean people would go to it for everything, giving massive amounts of power and influence to whoever has created or designed it, people who Timnit had already shown have very flawed views of where humanity must go in the future.\n",
    "\n",
    "Another thing Timnit discussed in her talks was the flaws in how the media view AI, discussing how the lack of knowledge on how it works and the promises from big companies that they are working on certain things will make investors unwilling to fund small organizations that are actually doing them, even when the large corporations end up making a poor quality product if they even deliver one at all.\n",
    "\n",
    "I think that I agree with Timnit on all her points. I think that the thing that people should take away from this is how vile the goals of some of these extremely influential tech people are, and just how much they are able to influence. I think that people also need to realize that for many of them, the creation of a powerful new AI system will not benefit them much, and that it will in reality only serve to further enrich the already wealthy.\n",
    "\n",
    "Learning from Timnit was very interesting. I found all of the things she brought up to be fascinating, but they left me rather disillusioned with what I have decided to do for a living. As someone who has always had doubts about what tech companies do to actually help people, having a lot of those doubts validated was rather discouraging for me. After her talks, I am very curious about how I can use my skills to help improve the world, and how I can make sure that a future employer will share these values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
